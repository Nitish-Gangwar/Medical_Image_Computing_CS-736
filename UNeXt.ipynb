{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_O35v8DClnuY"
   },
   "source": [
    "**Please run the cells marked ### RUN ### sequentially to get the final output**\n",
    "### Some points to consider before working on this project(These points are not necessary if the zip file is downloaded):\n",
    "* All of this work has been done on Google Colab. So, please run it on Google Colab.\n",
    "* Firstly clone the UNeXt repo and inside that directory create a folder namely \"inputs\". Inside \"inputs\" folder keep your dataset folder say \"BUSI\". Inside \"BUSI\" make two folders \"images\" and \"masks\".\n",
    "* Inside \"images\" store the images and inside \"masks\" folder create another directory say \"0\",\"1\",\"2\" the number of classes you have inside the dataset. \n",
    "* Inside each class store the respective class segmented maps with the same filename as the image in the \"images\" folder.(Do not use the double quotes while naming they have been used just for highlighting purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOpeWER-wxd9"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/jeya-maria-jose/UNeXt-pytorch\n",
    "%cd UNeXt-pytorch\n",
    "!mkdir inputs\n",
    "%cd inputs\n",
    "!mkdir Dataset_BUSI_with_GT\n",
    "%cd Dataset_BUSI_with_GT\n",
    "!mkdir images\n",
    "!mkdir masks\n",
    "%cd masks\n",
    "!mkdir 0\n",
    "%cd ../..\n",
    "!mkdir ISIC2018_Task1-2_Training_Input\n",
    "%cd ISIC2018_Task1-2_Training_Input\n",
    "!mkdir images\n",
    "!mkdir masks\n",
    "%cd masks\n",
    "!mkdir 0\n",
    "%cd ../../..\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHnOOmosTM-2"
   },
   "source": [
    "# This cell clones the UNeXt repo and downloads the data from **Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yJggqbZLZEO",
    "outputId": "18835b6a-c5ed-41a6-d136-b6c969f090be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'UNeXt-pytorch'...\n",
      "remote: Enumerating objects: 59, done.\u001b[K\n",
      "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
      "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
      "remote: Total 59 (delta 20), reused 26 (delta 5), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (59/59), done.\n",
      "/content/UNeXt-pytorch\n",
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1PgegjqOwaPAII3HfUaZyUFX6K8xVe5EG\n",
      "To: /content/UNeXt-pytorch/inputs.zip\n",
      "100% 875M/875M [00:10<00:00, 86.1MB/s]\n",
      "archs.py    environment.yml  LICENSE\t post_process.py  train.py\n",
      "config.py   imgs\t     losses.py\t __pycache__\t  utils.py\n",
      "dataset.py  inputs\t     metrics.py  README.md\t  val.py\n"
     ]
    }
   ],
   "source": [
    "### RUN ###\n",
    "# https://drive.google.com/file/d/1PgegjqOwaPAII3HfUaZyUFX6K8xVe5EG/view?usp=sharing\n",
    "!git clone https://github.com/jeya-maria-jose/UNeXt-pytorch\n",
    "%cd UNeXt-pytorch\n",
    "!pip install gdown -q\n",
    "!gdown --id 1PgegjqOwaPAII3HfUaZyUFX6K8xVe5EG\n",
    "!unzip -q inputs.zip\n",
    "!rm -rf inputs.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9Mows6OTqk8"
   },
   "source": [
    "## **This cell is for downloading the token from kaggle.json**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qg1mNrArbJjH"
   },
   "outputs": [],
   "source": [
    "#plant datset making connection to kaggle to download the dataset\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQkH27NVTzRF"
   },
   "source": [
    "## **This cell downloads the BUSI dataset from kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8b3KXjMybJld"
   },
   "outputs": [],
   "source": [
    "#plant dataset extracting the data using api from kaggle\n",
    "!kaggle datasets download -d aryashah2k/breast-ultrasound-images-dataset\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8XI1yd0Wb8w"
   },
   "source": [
    "# **Unzipping the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPhkKPoybJp3"
   },
   "outputs": [],
   "source": [
    "#unzipping plant dataset \n",
    "!unzip -q breast-ultrasound-images-dataset.zip\n",
    "!rm -rf breast-ultrasound-images-dataset.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cS-OeoDh4lAv"
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "url = \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Training_Input.zip\"\n",
    "wget.download(url, './')\n",
    "\n",
    "url = \"https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Training_GroundTruth.zip\"\n",
    "wget.download(url, './')\n",
    "\n",
    "!unzip -q ISIC2018_Task1-2_Training_Input.zip\n",
    "!rm -rf ISIC2018_Task1-2_Training_Input.zip\n",
    "!unzip -q ISIC2018_Task1_Training_GroundTruth.zip\n",
    "!rm -rf ISIC2018_Task1_Training_GroundTruth.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXDJ7BmbWsaP"
   },
   "source": [
    "# **Libraries required to run the code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ge2WJId_mgqj",
    "outputId": "0cdcdd59-2866-4813-fadd-98b0f6236d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm==0.3.2\n",
      "  Downloading timm-0.3.2-py3-none-any.whl (244 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |█▍                              | 10 kB 18.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 20 kB 23.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 30 kB 29.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 40 kB 28.2 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 51 kB 27.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 61 kB 31.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 71 kB 24.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 81 kB 25.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 92 kB 27.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 102 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 112 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 122 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 133 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 143 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 153 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 163 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 174 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 184 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 194 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 204 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 215 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 225 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 235 kB 26.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 244 kB 26.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2) (0.12.0+cu113)\n",
      "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from timm==0.3.2) (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->timm==0.3.2) (4.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.3.2) (2.23.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.3.2) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.3.2) (1.21.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.3.2) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.3.2) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.3.2) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm==0.3.2) (3.0.4)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.3.2\n",
      "Collecting mmcv\n",
      "  Downloading mmcv-1.5.0.tar.gz (530 kB)\n",
      "\u001b[K     |████████████████████████████████| 530 kB 29.5 MB/s \n",
      "\u001b[?25hCollecting addict\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv) (1.21.6)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv) (21.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv) (7.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv) (3.13)\n",
      "Collecting yapf\n",
      "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
      "\u001b[K     |████████████████████████████████| 190 kB 36.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv) (3.0.8)\n",
      "Building wheels for collected packages: mmcv\n",
      "  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mmcv: filename=mmcv-1.5.0-py2.py3-none-any.whl size=807180 sha256=2667e88a017b6fe64ee8275f1d96f8ced030cb9bb0dd93268798fa178d46ec57\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/b4/88/0fee9e050a776e49b7290c2853e8ec002eeb55d7f4a40cf78f\n",
      "Successfully built mmcv\n",
      "Installing collected packages: yapf, addict, mmcv\n",
      "Successfully installed addict-2.4.0 mmcv-1.5.0 yapf-0.32.0\n",
      "Collecting torch==1.7.1\n",
      "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (4.2.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0+cu113\n",
      "    Uninstalling torch-1.11.0+cu113:\n",
      "      Successfully uninstalled torch-1.11.0+cu113\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\n",
      "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\n",
      "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.7.1\n",
      "Collecting torchvision==0.8.2\n",
      "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 18.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (1.21.6)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
      "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->torchvision==0.8.2) (4.2.0)\n",
      "Installing collected packages: torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0+cu113\n",
      "    Uninstalling torchvision-0.12.0+cu113:\n",
      "      Successfully uninstalled torchvision-0.12.0+cu113\n",
      "Successfully installed torchvision-0.8.2\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 27.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.21.6)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.8 MB 1.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (4.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.4.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.8)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
      "  Attempting uninstall: albumentations\n",
      "    Found existing installation: albumentations 0.1.12\n",
      "    Uninstalling albumentations-0.1.12:\n",
      "      Successfully uninstalled albumentations-0.1.12\n",
      "Successfully installed albumentations-1.1.0 opencv-python-headless-4.5.5.64 qudida-0.0.4\n",
      "Found existing installation: opencv-python 4.1.2.30\n",
      "Uninstalling opencv-python-4.1.2.30:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python-4.1.2.30.dist-info/*\n",
      "  Would not remove (might be manually added):\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/config-3.py\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/config.py\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.abi3.so\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/gapi/__init__.py\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py2.py\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/load_config_py3.py\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/mat_wrapper/__init__.py\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/misc/__init__.py\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/misc/version.py\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/utils/__init__.py\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/version.py\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled opencv-python-4.1.2.30\n",
      "Collecting opencv-python==4.5.1.48\n",
      "  Downloading opencv_python-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (50.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 50.4 MB 1.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.1.48) (1.21.6)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.1.48\n",
      "Collecting PyYAML\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 24.5 MB/s \n",
      "\u001b[?25hInstalling collected packages: PyYAML\n",
      "Successfully installed PyYAML-6.0\n"
     ]
    }
   ],
   "source": [
    "### RUN ###\n",
    "!pip install timm==0.3.2\n",
    "!pip install mmcv\n",
    "!pip install torch==1.7.1\n",
    "!pip install torchvision==0.8.2\n",
    "!pip install -U albumentations\n",
    "!pip uninstall opencv-python\n",
    "!pip install opencv-python==4.5.1.48\n",
    "!pip install --ignore-installed PyYAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqttuihfkj85"
   },
   "source": [
    "## **Code for creating the required directory structure for ISIC Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSKbq-55_AWz"
   },
   "outputs": [],
   "source": [
    "# For ISIC 2018 dataset\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "src_path_images =\"./ISIC2018_Task1-2_Training_Input/\"\n",
    "src_path_masks = \"./ISIC2018_Task1_Training_GroundTruth/\"\n",
    "trg_path_images = \"./inputs/ISIC2018_Task1-2_Training_Input/images/\"\n",
    "trg_path_masks = \"./inputs/ISIC2018_Task1-2_Training_Input/masks/\"\n",
    "\n",
    "files = os.listdir(src_path_images)\n",
    "print(type(files))\n",
    "for f in files:\n",
    "    regex = r\".jpg$\"\n",
    "    if re.search(regex, f) != None: \n",
    "        shutil.move(os.path.join(src_path_images,f), trg_path_images)\n",
    "\n",
    "files = os.listdir(src_path_masks)\n",
    "for f in files:\n",
    "    regex = r\".png$\"\n",
    "    if re.search(regex, f) != None: \n",
    "        shutil.move(os.path.join(src_path_masks,f), trg_path_masks+\"0/\"+f.replace('_segmentation',''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCZfl-ANkuo5"
   },
   "source": [
    "## **Code for creating the directory structure for BUSI Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpEyzWwYCCsc",
    "outputId": "57276ab6-820d-486b-8ce9-6166b1bed130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# For BUSI dataset\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "src_path_benign =\"./Dataset_BUSI_with_GT/benign/\"\n",
    "src_path_malignant = \"./Dataset_BUSI_with_GT/malignant/\"\n",
    "src_path_normal = \"./Dataset_BUSI_with_GT/normal/\"\n",
    "trg_path_inputs = \"./inputs/Dataset_BUSI_with_GT/images/\"\n",
    "trg_path_masks = \"./inputs/Dataset_BUSI_with_GT/masks/\"\n",
    "\n",
    "files = os.listdir(src_path_benign)\n",
    "print(type(files))\n",
    "for f in files:\n",
    "    regex = r\"\\)_mask.png$\"\n",
    "    regex1 = r\"\\).png$\"\n",
    "    if re.search(regex, f) != None:\n",
    "        shutil.move(os.path.join(src_path_benign,f), trg_path_masks+\"0/\"+f.replace('_mask',''))\n",
    "    elif re.search(regex1, f) != None:\n",
    "        shutil.move(os.path.join(src_path_benign,f), trg_path_inputs)\n",
    "\n",
    "files = os.listdir(src_path_malignant)\n",
    "for f in files:\n",
    "    regex = r\"\\)_mask.png$\"\n",
    "    regex1 = r\"\\).png$\"\n",
    "    if re.search(regex, f) != None:\n",
    "        shutil.move(os.path.join(src_path_malignant,f), trg_path_masks+\"0/\"+f.replace('_mask',''))\n",
    "    elif re.search(regex1, f) != None:\n",
    "        shutil.move(os.path.join(src_path_malignant,f), trg_path_inputs)\n",
    "\n",
    "files = os.listdir(src_path_normal)\n",
    "for f in files:\n",
    "    regex = r\"\\)_mask.png$\"\n",
    "    regex1 = r\"\\).png$\"\n",
    "    if re.search(regex, f) != None or re.search(regex1, f) != None:\n",
    "        shutil.move(os.path.join(src_path_normal,f), trg_path_masks+\"0/\"+f.replace('_mask',''))\n",
    "    elif re.search(regex1, f) != None:\n",
    "        shutil.move(os.path.join(src_path_normal,f), trg_path_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tD9EqFUk3s0"
   },
   "source": [
    "## **Command to train the model with the specified parameters like model name, dataset name, etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_p9890RbJ1u"
   },
   "outputs": [],
   "source": [
    "### RUN ###\n",
    "# Run this command for BUSI dataset\n",
    "!python train.py --dataset Dataset_BUSI_with_GT --arch UNext --name Dataset_BUSI_with_GT --img_ext .png --mask_ext .png --lr 0.0001 --epochs 100 --input_w 256 --input_h 256 --b 8\n",
    "# Run this command for ISIC dataset\n",
    "#!python train.py --dataset ISIC2018_Task1-2_Training_Input --arch UNext --name ISIC2018_Task1-2_Training_Input --img_ext .jpg --mask_ext .png --lr 0.0001 --epochs 100 --input_w 256 --input_h 256 --b 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eME-QyHGlDfG"
   },
   "source": [
    "## **Command to generating the predictions over the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dokzBktZazaF"
   },
   "outputs": [],
   "source": [
    "### RUN ###\n",
    "# Run this command for validating BUSI dataset\n",
    "!python val.py --name Dataset_BUSI_with_GT\n",
    "# Run this command for validation ISIC dataset\n",
    "#!python val.py --name ISIC2018_Task1-2_Training_Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GssvmGOOZVC6",
    "outputId": "5d3f0f14-b96c-4911-def4-13f58ef5dbbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 28 00:21:39 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is enabled.\n",
    "!nvidia-smi\n",
    "!lscpu |grep 'Model name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbRkkS3GslSE"
   },
   "source": [
    "# This code snippet will read the images from the output folder and from original segmented **folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYjhXiJ4DNOC"
   },
   "outputs": [],
   "source": [
    "### RUN ###\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "predmaskarr=[]\n",
    "origmaskarr=[]\n",
    "outpath ='/content/UNeXt-pytorch/outputs/ISIC2018_Task1-2_Training_Input/0/'\n",
    "#inpath = '/content/UNeXt-pytorch/inputs/Dataset_BUSI_with_GT/masks/0/'\n",
    "inpath = '/content/UNeXt-pytorch/inputs/ISIC2018_Task1-2_Training_Input/masks/0/'\n",
    "for img1 in os.listdir(outpath):\n",
    "  im1=cv2.imread(outpath+img1)\n",
    "  predmaskarr.append(np.array(im1))\n",
    "  for img2 in os.listdir(inpath):\n",
    "    #print(img1,img2)\n",
    "    if(img1[:-3] == img2[:-3]):\n",
    "      im2=cv2.imread(inpath+img2)\n",
    "      imresized = cv2.resize(im2, (256,256), interpolation = cv2.INTER_NEAREST)\n",
    "      #print(np.array(imresized).shape)\n",
    "      origmaskarr.append(np.array(imresized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DoU9kgScLXcj",
    "outputId": "5849fccc-5f27-4fb9-a5c1-46ee77f63a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(519, 256, 256, 3)\n",
      "(519, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "### RUN ###\n",
    "print(np.array(predmaskarr).shape)\n",
    "print(np.array(origmaskarr).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1_PkzPqTDem"
   },
   "source": [
    "# Computes the F1-score **here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "NIewAPKQMztw",
    "outputId": "736c3f19-3415-4373-f20c-4d1bb06d0e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942051176390896\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nprint(\"Precision Score : \",precision_score(origmaskarr,predmaskarr,pos_label=\\'positive\\'))\\nprint(\"Recall Score :\" , recall_score(origmaskarr,predmaskarr, pos_label=\\'positive\\') )\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RUN ###\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "f1=0\n",
    "\n",
    "for i in range(0,len(predmaskarr)):\n",
    "  f1= f1+f1_score(origmaskarr[i].flatten(),predmaskarr[i].flatten(),average='micro')\n",
    "f1=f1/len(predmaskarr)\n",
    "print(f1)\n",
    "'''\n",
    "print(\"Precision Score : \",precision_score(origmaskarr,predmaskarr,pos_label='positive'))\n",
    "print(\"Recall Score :\" , recall_score(origmaskarr,predmaskarr, pos_label='positive') )\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "UNeXt.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
